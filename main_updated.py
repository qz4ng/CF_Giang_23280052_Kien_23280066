# main_updated.py
import pandas as pd
import numpy as np
import config_updated as config  # Import file config m·ªõi

# --- IMPORT C√ÅC MODULE ---
from data_layer.loader import DataLoader
from data_layer.processor import DataProcessor

# Feature Layer (Bao g·ªìm c√°c b·∫£n n√¢ng c·∫•p)
from feature_layer.clustering import MarketCluster
from feature_layer.pairs_updated import PairsIndicatorsUpdated # D√πng b·∫£n Updated
from feature_layer.trend import TrendIndicators
from feature_layer.momentum import MomentumIndicators
from feature_layer.volatility import VolatilityIndicators

# Model Layer (AI)
from model_layer.data_handler_updated import DataHandlerUpdated # D√πng b·∫£n Updated
from model_layer.regressor_updated import RandomForestTrader    # D√πng Random Forest

# Portfolio Layer (Qu·∫£n l√Ω v·ªën)
from portfolio_layer.allocator import StrategyAllocator

def run_advanced_system():
    print("\n" + "="*70)
    print(" Ch·∫°y m√¥ h√¨nh")
    print("="*70)

    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 1: T·∫¢I & X·ª¨ L√ù D·ªÆ LI·ªÜU
    # --------------------------------------------------------------------------
    print("\n[1/6] t·∫£i v√† l√†m s·∫°ch d·ªØ li·ªáu")
    loader = DataLoader(config.START_DATE, config.END_DATE)
    raw_data = loader.download_data(config.TICKERS)
    
    processor = DataProcessor()
    processed_data = processor.process_all(raw_data)
    
    if len(processed_data) == 0:
        print(" L·ªói: Kh√¥ng c√≥ d·ªØ li·ªáu sau khi x·ª≠ l√Ω.")
        return

    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 2: PH√ÇN C·ª§M TH·ªä TR∆Ø·ªúNG (CLUSTERING)
    # --------------------------------------------------------------------------
    # M·ª•c ti√™u: Tr√°nh ch·ªçn to√†n b·ªô c·∫∑p trong c√πng 1 ng√†nh (R·ªßi ro t·∫≠p trung)
    print(f"\n[2/6] Ph√¢n c·ª•m {len(processed_data)} m√£ th√†nh {config.N_CLUSTERS} nh√≥m h√†nh vi")
    
    cluster_algo = MarketCluster(n_clusters=config.N_CLUSTERS)
    cluster_map = cluster_algo.cluster_stocks(processed_data)
    
    # T·ªï ch·ª©c l·∫°i dictionary: {Group_ID: [List Tickers]}
    clusters = {i: [] for i in range(config.N_CLUSTERS)}
    for ticker, group_id in cluster_map.items():
        clusters[group_id].append(ticker)

    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 3: CH·ªåN C·∫∂P TINH HOA & T√çNH FEATURE (PAIR SELECTION)
    # --------------------------------------------------------------------------
    print("\n[3/6] Ch·ªçn l·ªçc c·∫∑p t·ªët nh·∫•t & T√≠nh to√°n ch·ªâ b√°o k·ªπ thu·∫≠t")
    
    pairs_logic = PairsIndicatorsUpdated()
    trend = TrendIndicators()
    mom = MomentumIndicators()
    vol = VolatilityIndicators()
    
    # Danh s√°ch ch·ª©a th√¥ng tin ƒë·∫ßy ƒë·ªß ƒë·ªÉ ƒë∆∞a v√†o AI
    # M·ªói ph·∫ßn t·ª≠ l√† 1 dict ch·ª©a: Data, Model, Handler, Tickers...
    portfolio_candidates = [] 
    
    for group_id, tickers_in_group in clusters.items():
        # B·ªè qua nh√≥m qu√° √≠t m√£
        if len(tickers_in_group) < 2: continue
        
        # L·ªçc data ch·ªâ c·ªßa nh√≥m n√†y
        group_data = {t: processed_data[t] for t in tickers_in_group}
        
        # L·∫•y Top 1 c·∫∑p t·ªët nh·∫•t trong nh√≥m n√†y (ƒë·ªÉ ƒë·∫°i di·ªán)
        # (C√≥ th·ªÉ s·ª≠a th√†nh top_n=2 n·∫øu mu·ªën ƒëa d·∫°ng h∆°n n·ªØa)
        best_pairs, p_vals = pairs_logic.find_top_n_pairs(group_data, top_n=1)
        
        if not best_pairs:
            print(f"   Nh√≥m {group_id}: Kh√¥ng t√¨m th·∫•y c·∫∑p ƒë·ªìng t√≠ch h·ª£p n√†o.")
            continue
            
        pair = best_pairs[0]
        p_val = p_vals[0]
        print(f"   Nh√≥m {group_id}: Ch·ªçn c·∫∑p {pair} (p-value: {p_val:.5f})")
        
        # --- T√çNH TO√ÅN FEATURE K·ª∏ THU·∫¨T ---
        df1 = processed_data[pair[0]]
        df2 = processed_data[pair[1]]
        
        # Th√™m RSI, MACD, Bollinger... cho t·ª´ng m√£ l·∫ª TR∆Ø·ªöC khi g·ªôp
        for df in [df1, df2]:
            df = trend.add_macd(df)
            df = trend.add_sma_distance(df)
            df = mom.add_rsi(df)
            df = vol.add_bollinger_bands(df)
            
        # --- T√çNH SPREAD & Z-SCORE (D√ôNG ROLLING BETA) ---
        # ƒê√¢y l√† c·∫£i ti·∫øn quan tr·ªçng so v·ªõi Static Beta
        df_pair, avg_beta = pairs_logic.calculate_rolling_spread(
            df1, df2, window=config.ROLLING_WINDOW
        )
        
        # L∆∞u v√†o danh s√°ch ch·ªù hu·∫•n luy·ªán
        portfolio_candidates.append({
            'tickers': pair,
            'data': df_pair,
            'group': group_id,
            'beta': avg_beta
        })

    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 4: HU·∫§N LUY·ªÜN AI (RANDOM FOREST)
    # --------------------------------------------------------------------------
    print(f"\n[4/6] Hu·∫•n luy·ªán m√¥ h√¨nh (Random Forest) cho {len(portfolio_candidates)} c·∫∑p")
    
    for item in portfolio_candidates:
        pair_name = f"{item['tickers'][0]}-{item['tickers'][1]}"
        df = item['data']
        
        # 1. Chu·∫©n b·ªã d·ªØ li·ªáu (T·∫°o Lags, Rolling Stats...)
        handler = DataHandlerUpdated()
        X, y = handler.create_dataset(df, target_col='Spread_Z', lags=config.LAG_DAYS)
        
        # 2. Chia t·∫≠p Train/Test & Scale
        X_train, X_test, y_train, y_test = handler.split_data(X, y)
        
        # 3. Kh·ªüi t·∫°o & Train Model
        rf_model = RandomForestTrader()
        rf_model.train(X_train, y_train)
        
        # 4. ƒê√°nh gi√° s∆° b·ªô
        print(f"   -> ƒê√°nh gi√° {pair_name}:")
        preds = rf_model.predict(X_test)
        rf_model.evaluate(y_test, preds, pair_name=pair_name)
        
        # 5. L∆∞u Model v√† Handler v√†o item ƒë·ªÉ d√πng cho b∆∞·ªõc Allocator
        item['model'] = rf_model
        item['handler'] = handler
        
        # (Optional) Xem AI ƒëang quan t√¢m ch·ªâ b√°o n√†o nh·∫•t
        # rf_model.show_feature_importance()

    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 5: PH√ÇN B·ªî V·ªêN (PORTFOLIO OPTIMIZATION)
    # --------------------------------------------------------------------------
    print("\n[5/6] T√≠nh to√°n t·ª∑ tr·ªçng v·ªën t·ªëi ∆∞u (Mean-Variance + Dynamic Risk)")
    
    # Kh·ªüi t·∫°o Allocator c√≥ b·∫≠t ch·∫ø ƒë·ªô Qu·∫£n l√Ω r·ªßi ro (risk_manager=True)
    allocator = StrategyAllocator(risk_manager=True)
    
    # H√†m n√†y s·∫Ω t·ª± ƒë·ªông:
    # 1. D√πng AI d·ª± b√°o Z-score ng√†y ti·∫øp theo
    # 2. D√πng Risk Manager ƒëo ƒë·ªô tin c·∫≠y
    # 3. D√πng Optimizer t√≠nh t·ª∑ tr·ªçng Sharpe t·ªët nh·∫•t
    final_weights = allocator.allocate_capital(portfolio_candidates)

    # --------------------------------------------------------------------------
    # B∆Ø·ªöC 6: B√ÅO C√ÅO K·∫æT QU·∫¢
    # --------------------------------------------------------------------------
    print("\n" + "="*70)
    print(" KHUY·∫æN NGH·ªä PH√ÇN B·ªî DANH M·ª§C (PORTFOLIO ALLOCATION)")
    print("="*70)
    
    total_alloc = 0
    for i, item in enumerate(portfolio_candidates):
        pair_str = f"{item['tickers'][0]} & {item['tickers'][1]}"
        weight_pct = final_weights[i] * 100
        group_id = item['group']
        beta_val = item['beta']
        
        if weight_pct > 0.1: # Ch·ªâ in nh·ªØng c·∫∑p c√≥ t·ª∑ tr·ªçng ƒë√°ng k·ªÉ
            print(f" üîπ Nh√≥m {group_id} | {pair_str:<20} | T·ª∑ tr·ªçng: {weight_pct:6.2f}% | Beta TB: {beta_val:.2f}")
            total_alloc += weight_pct
            
    print("-" * 70)
    print(f" T·ªïng t·ª∑ tr·ªçng ƒë·∫ßu t∆∞: {total_alloc:.2f}% (C√≤n l·∫°i {100-total_alloc:.2f}% Ti·ªÅn )")
    print("="*70)

if __name__ == "__main__":
    run_advanced_system()